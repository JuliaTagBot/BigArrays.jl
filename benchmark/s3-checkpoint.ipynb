{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workers() = [2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(6)                                                                                                                                     \n",
    "@show workers()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutout speed: 11.34904914062073 MB/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "run_trials (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BigArrays, GSDicts, S3Dicts, BigArrays.BinDicts                  \n",
    "using OffsetArrays                 \n",
    "using Plots                                                            \n",
    "                                                                       \n",
    "                                                                       \n",
    "ba = BigArray(S3Dict(\"s3://neuroglancer/s1_v1/image/6_6_30/\"))         \n",
    "#const img = ba[4097:4096+1024, 4097:4096+1024, 1025:1024+512]         \n",
    "const img = ba[4097:4096+512, 4097:4096+512, 1025:1024+512] |> parent  \n",
    "#using HDF5                                                                                                                                    \n",
    "#rm(\"/tmp/img.h5\")                                                                                                                             \n",
    "#h5write(\"/tmp/img.h5\", \"image\", img);                                 \n",
    "                                                                       \n",
    "# prepare directory                \n",
    "tempDir = tempname()                                                   \n",
    "const KEY = \"6_6_30\"                                                                                                                           \n",
    "const infoPath = joinpath(tempDir,\"info\")                              \n",
    "const datasetDir = joinpath(tempDir, KEY)                         \n",
    "mkdir(tempDir)                                                         \n",
    "mkdir(datasetDir)                  \n",
    "const CHUNK_SIZE = [256,256,32]    \n",
    "const TASK_NUM = 20                \n",
    "const TEST_NUM = 3                 \n",
    "\n",
    "function save(ba::BigArray, img)   \n",
    "    sz = size(img)                 \n",
    "    t1 = time()                    \n",
    "    ba[1:sz[1], 1:sz[2], 1:sz[3]] = img                                \n",
    "    time()-t1                      \n",
    "end                                \n",
    "\n",
    "function cutout(ba::BigArray, sz)                                                                                           \n",
    "    t1 = time()                    \n",
    "    ba[1:sz[1], 1:sz[2], 1:sz[3]]  \n",
    "    time()-t1                      \n",
    "end                                \n",
    "\n",
    "function test(ba::BigArray, img; testTime = 5)                         \n",
    "    tsList = Vector()              \n",
    "    tcList = Vector()              \n",
    "    for i in 1:TEST_NUM            \n",
    "        push!(tsList, save(ba, img))                                   \n",
    "        push!(tcList, cutout(ba, size(img)))                           \n",
    "    end                            \n",
    "    totalSize = length(img)*sizeof(eltype(img)) / 1000/1000            \n",
    "    totalSize / median(tsList), totalSize / median(tcList)             \n",
    "end                                \n",
    "\n",
    "function run_trials(chunkSize; testTime=5)                             \n",
    "    sz = size(img)                 \n",
    "    dataSize = length(img) * sizeof(eltype(img)) / 1000 / 1000 # MB    \n",
    "    infoString = \"\"\"{\"num_channels\": 1, \"type\": \"image\", \"data_type\": \"uint8\", \"scales\":[{\"encoding\": \"raw\", \"chunk_sizes\": [$(chunkSize)], \"key\": \"$(KEY)\", \"resolution\": [6, 6, 30], \"voxel_offset\": [0, 0, 0], \"size\": [12286, 11262,2046]}]}\"\"\"\n",
    "    open( infoPath, \"w\" ) do f  \n",
    "        write(f, infoString)       \n",
    "    end                            \n",
    "#     gsDir = \"gs://seunglab/jpwu/benchmark/image\"                       \n",
    "    s3Dir = \"s3://seunglab/jpwu/benchmark/image\"                       \n",
    "    #run(`gsutil cp $(infoPath) $(joinpath(gsDir, \"info\"))`)           \n",
    "    run(`aws s3 cp --content-type=text/plain $(infoPath) $(joinpath(s3Dir, \"info\"))`)           \n",
    "\n",
    "    # test local speed             \n",
    "#     ba_local = BigArray(BinDict(datasetDir))                                                                                          \n",
    "#     ss,sc = test(ba_local, img; testTime=testTime)                     \n",
    "\n",
    "    # test GS speed                \n",
    "\n",
    "    #ba_gs = BigArray(GSDict(joinpath(gsDir, KEY)); taskNum=taskNum)   \n",
    "    #ss, sc = test(ba_gs, img)                                   \n",
    "\n",
    "    # test S3 speed                \n",
    "    ba_s3 = BigArray(S3Dict(joinpath(s3Dir, KEY)))   \n",
    "    ss, sc = test(ba_s3, img; testTime=testTime) \n",
    "\n",
    "    #df[:save_speed] = ts_local#[ts_local, ts_gs, ts_s3]               \n",
    "    #df[:cutout_speed] = tc_local#[tc_local, tc_gs, tc_s3]             \n",
    "    #@show df   \n",
    "    @show ss\n",
    "    @show sc\n",
    "    return ss, sc                  \n",
    "end                                \n",
    "\n",
    "# taskNumList = [1, 5, 10, 15, 20, 25, 30]                             \n",
    "# #taskNumList = [1, 10, 20]       \n",
    "# ss_list = Vector()               \n",
    "# sc_list = Vector()               \n",
    "# for taskNum in taskNumList       \n",
    "#     @show taskNum                \n",
    "#     ss, sc = run_trials(CHUNK_SIZE, taskNum; testTime=7)             \n",
    "#     push!(ss_list, ss)           \n",
    "#     push!(sc_list, sc)           \n",
    "# end                              \n",
    "\n",
    "# using Plots                      \n",
    "# plot(taskNumList, hcat(ss_list, sc_list))                            \n",
    "# #plot(taskNumList, ss_list)      \n",
    "\n",
    "# #plotly()                        \n",
    "# gr()                             \n",
    "# #pyplot()                        \n",
    "# #plot(taskNumList, ss_list)      \n",
    "# plot(taskNumList, hcat(ss_list, sc_list), m=(8,:auto), legend=true,  \n",
    "#         lab=[\"saving\", \"cutout\"],\n",
    "#         xlabel=\"task number\",    \n",
    "#         ylabel=\"speed (MB/s)\")   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunkSize = [256, 256, 1]\n",
      "upload: ../../../../../../../tmp/juliaOo4OJO/info to s3://seunglab/jpwu/benchmark/image/info\n"
     ]
    }
   ],
   "source": [
    "chunkSizeList = [[256,256,1], [256,256,8], [256,256,16], [256,256,32], [256,256,64], [256,256,128], [256,256,256]]                             \n",
    "\n",
    "ss_list2 = Vector()                \n",
    "sc_list2 = Vector()                \n",
    "for chunkSize in chunkSizeList     \n",
    "    @show chunkSize                \n",
    "    ss, sc = run_trials(chunkSize; testTime=5)                         \n",
    "    push!(ss_list2, ss)            \n",
    "    push!(sc_list2, sc)            \n",
    "end  \n",
    "using JLD2\n",
    "@save \"bigarray.jld\" ss_list2 sc_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(map(string, chunkSizeList), hcat(ss_list2, sc_list2), m=(8,:auto), legend=true,                                                           \n",
    "        lab=[\"saving\", \"cutout\"],  \n",
    "        xlabel=\"chunk size\",       \n",
    "        ylabel=\"speed (MB/s)\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
